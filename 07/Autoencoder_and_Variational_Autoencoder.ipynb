{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Eblrou57f2Pe"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    " \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    " \n",
    "from sklearn.manifold import TSNE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTOniXCS1oAx"
   },
   "source": [
    "### Helper function for timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mPi1gyvc1oAz"
   },
   "outputs": [],
   "source": [
    "class Timer():\n",
    "    \"\"\"\n",
    "    A small class to measure time during training.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Start a new timer\n",
    "        \"\"\"\n",
    "        if self._start_time is not None:\n",
    "            print(f\"Timer is running. Use .stop() to stop it\")\n",
    "            return None\n",
    "\n",
    "        self._start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"\n",
    "        Stop the timer, and report the elapsed time\n",
    "        \"\"\"\n",
    "        if self._start_time is None:\n",
    "            print(f\"Timer is not running. Use .start() to start it\")\n",
    "            return 0\n",
    "    \n",
    "        elapsed_time = time.perf_counter() - self._start_time\n",
    "        self._start_time = None\n",
    "        return elapsed_time  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAaCpMAB3yM5"
   },
   "source": [
    "# Data Pipeline\n",
    "\n",
    "- Don't normalize the data to have zero mean and unit variance. Min-max scaling (0-1), i.e. dividing by 255 works better for VAE!\n",
    "\n",
    "- Shuffle, batch and prefetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I7l6tCIXzs6j"
   },
   "outputs": [],
   "source": [
    "def preprocess_tfds(dataset, batch_size=32, buffer_size=1024, prefetch_factor=tf.data.experimental.AUTOTUNE, shuffle=True):\n",
    "    '''\n",
    "    Create an input pipeline from tf.dataset. \n",
    "    Adjusted to only take input as there are no labels for autoencoders.\n",
    "    Does only do input pipeline optimization when desired (inputs are not None)\n",
    "\n",
    "    :param dataset: tf.dataset to preprocess\n",
    "    :param batch_size: int, default batch size is 64\n",
    "    :param buffer_size: int, default is 1024\n",
    "    :param prefetch_factor: int, default prefetch size is TF autotune\n",
    "    :returns: preprocessed tf.dataset\n",
    "    ''' \n",
    "    \n",
    "    # only use batching if shuffle is set to False\n",
    "    if not shuffle:\n",
    "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    # casting of the images to float32 and expanding dim since there is no channel dim\n",
    "    # dividing by 255 to min-max scale the input\n",
    "    dataset = dataset.map(lambda img, label: (tf.cast(img, tf.float32)/255, tf.cast(label, tf.uint8)), \n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # prefetch the dataset using AUTOTUNE to automatically find the optimal number of batches to prefetch\n",
    "    if not prefetch_factor is None:\n",
    "        dataset = dataset.prefetch(prefetch_factor)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359,
     "referenced_widgets": [
      "adfc802f6b224aabb69a90c004e822a7",
      "d7c4e0f5448d4f4a94be99ffbcc65bb5",
      "5a93ac3a8d084ad6ad7466789611421a",
      "45e51560b0344064b2d84d032d9707ea",
      "6be9064c555e43e4b277244e626882c7",
      "1636a3aa870b458fa413301b307f512f",
      "dcd2f74fbd3346da9d39cce1e4b2e463",
      "a23418c746a04b7190e48c77279d7ddf",
      "417d43d404384f93a55340404abac399",
      "1ea884b07a564303b74382607518ea69",
      "c55bbc1570f2482cb48cc0ee255cc852",
      "c9b7dafd4802445889b49a824eb0fbad",
      "aa293d870d2b494aa01226dfc38ee6bd",
      "d6cbbe9fece9467d972486c68fbb4542",
      "2b00122e902f47acb3efbf06b99d3b28",
      "760c95c778814d9c8795db0583c47ca3",
      "8f58b8e60c6a41cea8e55ffaee31055c",
      "6b24a422c3f64a8ca9844eb9b180ca41",
      "fb075f44d08647d7b781913516911e18",
      "190815918d004dd7969b9cb7a503f333",
      "2cd9ae82d0a24afb8aeabb51928ada0a",
      "c72192de951442e08987b349d2c0c4c2",
      "f55a71d914dc4383bccd03933f5e0fb6",
      "101a4c28016c4db2aebe5cf60f15a35a",
      "65d1413674744bac90d12314e5e90bb9",
      "9567d646840543248b0dc8d3d6a09a4d",
      "7489d97a46fb4b3f9caf473d8a2d8501",
      "a47caff0061848989b819e522d5892bc",
      "b65afa82be234799b3d4643ab6c024c0",
      "e12bfb8509394632be6df6925c55a919",
      "19949c5144fe43e4b3d82815f7261a78",
      "57197cd3c12749bcbcbaf29115822a24",
      "a4ded38fb51343d68abf61b666d8076e",
      "fc4c2575df944c7e8e7fd67bf1d4e76c",
      "961fcc4f2bca4014a21795406dc34269",
      "d12a7e6f15484c82a891d45e7a1db468",
      "c0545e3500824a198185c2c9e9ef4f95",
      "f31e0b6fecec44048fca88c5bb66add1",
      "aac72d8c71fa4e0e99e8d0cf705d3aec",
      "16ed9de3c566481d8f7469b3d57e3612",
      "06891ddacfc245c1a860e46f300b90eb",
      "6489162bfa7f4b9b932559142bb81b0a",
      "4421e5821c06440bbf4be497337e7943",
      "ebcc7fe1d0524f29919f29cc827121eb",
      "c1d03b23f9994dd594d5fd1f5f9e22a0",
      "71d177dbec114f2cbf74135153e733af",
      "070b2469aa2d444ab1e8a0cb6ea5b30b",
      "bd32c1cc2a9b4df786dc300f7b22347c",
      "7f21df01f45d4188b10bb101bcd5b881",
      "2266b6247f094792a175b1d9110cb726",
      "e32119b111464c1fa2a5126c53b99fdd",
      "cbf40dd55fe94557b07714399f80b5b3",
      "ee04a7ed1d6e442a804e4d349ad03f6a",
      "37370fbdcc6b450b9e70107b98cba3de",
      "a51383a98da64edb8d67a4202e98ad91",
      "71602b6acecd4893925e5e91a72b3dc1"
     ]
    },
    "id": "h1jjCW0WM0X3",
    "outputId": "261449f4-3994-4931-8116-ef98f86ab0d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 29.45 MiB (download: 29.45 MiB, generated: 36.42 MiB, total: 65.87 MiB) to /home/janosch/tensorflow_datasets/fashion_mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5868de39e9e3478f8daeda26986b8b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdb6e10694c49a1a3dc06f839c3100d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ff4337607d4660ac464039703367b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling fashion_mnist-train.tfrecord...:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling fashion_mnist-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to /home/janosch/tensorflow_datasets/fashion_mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## label codes for later analysis/visualization of encoded dataset\n",
    "label_code = ['T-Shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "\n",
    "# load the entire dataset from tfds (you can also get fashion_mnist from keras)\n",
    "train_ds, test_ds = tfds.load('fashion_mnist', \n",
    "                              split=['train', 'test'], \n",
    "                              as_supervised=True, \n",
    "                              shuffle_files=False)\n",
    "\n",
    "\n",
    "train_ds = preprocess_tfds(train_ds)\n",
    "test_ds = preprocess_tfds(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e59bjKV2kvA7"
   },
   "source": [
    "# 2.1. CNN Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wdc-m_ETgFoP"
   },
   "outputs": [],
   "source": [
    "class CNN_Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(CNN_Encoder, self).__init__()\n",
    "        \n",
    "        self.layers = []\n",
    "        \n",
    "        # (2,2) strided convolution to downsample\n",
    "        # padding=same for padding of the input image\n",
    "        \n",
    "        self.layers.append(tf.keras.layers.Conv2D(filters=32,\n",
    "                                                  kernel_size=(3,3),\n",
    "                                                  strides=(2,2),\n",
    "                                                  padding='same',\n",
    "                                                  input_shape=input_dim))  \n",
    "        self.layers.append(tf.keras.layers.BatchNormalization())\n",
    "        self.layers.append(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        self.layers.append(tf.keras.layers.Conv2D(filters=64,\n",
    "                                                  kernel_size=(3,3),\n",
    "                                                  strides=(2,2),\n",
    "                                                  padding='same'))  \n",
    "        self.layers.append(tf.keras.layers.BatchNormalization())\n",
    "        self.layers.append(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        # dense layer to set dimension\n",
    "        self.layers.append(tf.keras.layers.Flatten())\n",
    "        self.layers.append(tf.keras.layers.Dense(latent_dim, activation='relu'))\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        for layer in self.layers:\n",
    "            try:  # training argument only for BN layer\n",
    "                x = layer(x, training) \n",
    "            except:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, latent_dim, output_dim, restore_shape):\n",
    "        super(CNN_Decoder, self).__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        # dense layer to restore dim of flattend data\n",
    "        self.layers.append(tf.keras.layers.Dense(units=int(tf.math.reduce_prod((restore_shape))),\n",
    "                                                 input_shape=(latent_dim,)))\n",
    "        self.layers.append(tf.keras.layers.BatchNormalization())\n",
    "        self.layers.append(tf.keras.layers.Activation('relu'))\n",
    "        \n",
    "        # reshape to 3 dim with depth dim again\n",
    "        self.layers.append(tf.keras.layers.Reshape(target_shape=restore_shape))\n",
    "        \n",
    "        # (2,2) strided transposed conv to upsample \n",
    "        \n",
    "        self.layers.append(tf.keras.layers.Conv2DTranspose(filters=32,\n",
    "                                                           kernel_size=(3,3),\n",
    "                                                           strides=(2,2),\n",
    "                                                           padding='same'))\n",
    "        self.layers.append(tf.keras.layers.BatchNormalization())\n",
    "        self.layers.append(tf.keras.layers.Activation('relu'))\n",
    "       \n",
    "        # restore image by convolution with image size\n",
    "        self.layers.append(tf.keras.layers.Conv2DTranspose(filters=1,\n",
    "                                                  kernel_size=(3,3),\n",
    "                                                  strides=(2,2),\n",
    "                                                  padding='same'))  \n",
    "        self.layers.append(tf.keras.layers.BatchNormalization())\n",
    "        self.layers.append(tf.keras.layers.Activation('sigmoid'))\n",
    "       \n",
    "    def call(self, x, training=False):\n",
    "        for layer in self.layers:\n",
    "            try:  # training argument only for BN layer\n",
    "                x = layer(x, training) \n",
    "            except:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "class CNN_Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim, restore_shape=(7,7,64)):\n",
    "        super(CNN_Autoencoder, self).__init__()\n",
    "        # encoder and decoder are symmetric\n",
    "        self.encoder = CNN_Encoder(input_dim=input_dim,\n",
    "                                   latent_dim=latent_dim)\n",
    "        self.decoder = CNN_Decoder(latent_dim=latent_dim,\n",
    "                                   output_dim=input_dim,\n",
    "                                   restore_shape=restore_shape)\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        x = self.encoder(x, training)\n",
    "        self.latent_repr = x  # keep latent_repr as property in case it should be analyzed\n",
    "        x = self.decoder(x, training)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo4UOkpz5Fef"
   },
   "source": [
    "## Reconstructed image *before* training the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "zebOBir0aN6m",
    "outputId": "559ea8b7-f9c2-4979-9d7e-6e6e2879f65f",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "autoencoder = CNN_Autoencoder((None,28,28,1), latent_dim)\n",
    "first_img = 0\n",
    "\n",
    "# try autoencoder before training\n",
    "for img, label in train_ds.take(1):\n",
    "    plt.figure(figsize=(9, 3))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(img[first_img,:,:,0], cmap='gray')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.title('Reconstructed image')\n",
    "    plt.imshow(autoencoder(img)[first_img,:,:,0], cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1q1xd8v4tSa"
   },
   "source": [
    "# Defining Train and Evaluation steps\n",
    "- evaluation step outputs image and reconstructed image for visualization\n",
    "- epoch is done inside train_step, so iterating over train data is done inside a function with @tf.function decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4fZ7pKO2bzRM"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_AE(model, train_ds, loss_function, optimizer, train_loss_metric):\n",
    "    '''\n",
    "    Training for one epoch. Adjusted for Autoencoder as there are no acc_metric.\n",
    "    '''\n",
    "    for img, label in train_ds:  # there are no (input,label) pairs\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            prediction = model(img, training=True)\n",
    "            loss = loss_function(img, prediction) \n",
    "\n",
    "        # backward pass\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        train_loss_metric.update_state(loss)\n",
    "\n",
    "@tf.function\n",
    "def eval_step_AE(model, ds, loss_function, loss_metric):\n",
    "    '''\n",
    "    Evaluate without training. Adjusted for autoencoder. \n",
    "    Return a random image and reconstructed version of it.\n",
    "    '''\n",
    "    prediction = 0.0\n",
    "    img = 0.0\n",
    "\n",
    "    for img, label in ds:\n",
    "        # forward pass\n",
    "        prediction = model(img, training=False)\n",
    "        # update metrics\n",
    "        loss = loss_function(img, prediction)\n",
    "        loss_metric.update_state(loss)\n",
    "        \n",
    "    return img, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckV4nFI_5-MI"
   },
   "source": [
    "## Setting the hyperparameters and instantiating the Autoencoder\n",
    "\n",
    "- use build method with input shape so you can make use of the summary() method.\n",
    "\n",
    "- For the summary to work, your layers must call every keras layer that is instantiated (layers that are defined in __init__ must be used in the call method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOCXSaKyb9Os",
    "outputId": "502ba0b5-36ac-4bfb-dad9-7f8effed9d07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn__autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cnn__encoder (CNN_Encoder)   multiple                  50570     \n",
      "_________________________________________________________________\n",
      "cnn__decoder (CNN_Decoder)   multiple                  65925     \n",
      "=================================================================\n",
      "Total params: 116,495\n",
      "Trainable params: 109,965\n",
      "Non-trainable params: 6,530\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# @Hyperparameter\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "timer = Timer()\n",
    "\n",
    "# Define @model\n",
    "model_AE = CNN_Autoencoder(input_dim=(None,28,28,1), latent_dim=10)\n",
    "# Define @loss function\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "# Define @optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "# get summary of the model\n",
    "input_shape = (None,28,28,1) # None for batch size\n",
    "model_AE.build(input_shape) # needed for summary\n",
    "model_AE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gNtjK-Z6wVo"
   },
   "source": [
    "Defining the metrics so we can use them with tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oW-cXAg7csU3"
   },
   "outputs": [],
   "source": [
    "train_loss_metric = tf.keras.metrics.Mean('train_loss')\n",
    "test_loss_metric = tf.keras.metrics.Mean('test_loss')\n",
    "\n",
    "# Initialize lists for later visualization.\n",
    "train_losses_AE = []\n",
    "test_losses_AE = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TCN7f4D68Dr"
   },
   "source": [
    "## Train the Autoencoder\n",
    "\n",
    "- Train and test metric objects are updated with the method **update_state(loss)** inside the train_step and eval_step functions. \n",
    "- After one train_step (one epoch) we can get the result of a metric by using the **result()** method. This way we can also store them in an array or a list for visualization with matplotlib or seaborn.\n",
    "- The metrics must be reset after each epoch using the **reset_states()** method.\n",
    "\n",
    "## Visualize during training\n",
    "\n",
    "- Because our eval_step function returns an image batch and the model's reconstruction of it, we can visualize them in each epoch. \n",
    "- Note that it's always a different image due to shuffling. It's possible to also set a fixed image that will be reconstructed, so you can better compare between epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oyIT-9k4c4WF",
    "outputId": "bde21376-245d-49ab-b2a3-85d0860d0692",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] - Evaluating the Dataset on the cnn__autoencoder before training.\n",
      "train_loss: 0.1704, test_loss: 0.1697\n",
      "\n",
      "[EPOCH] ____________________0____________________\n",
      "[0] - Finished Epoch in 22.31 seconds - train_loss: 0.0364; test_loss: 0.0235\n",
      "\n",
      "[INFO] - Total time elapsed: 0.5138 min. Total time remaining: 12.3310 min.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH] ____________________1____________________\n",
      "[1] - Finished Epoch in 21.79 seconds - train_loss: 0.0207; test_loss: 0.0189\n",
      "\n",
      "[EPOCH] ____________________2____________________\n"
     ]
    }
   ],
   "source": [
    "print(f'[INFO] - Evaluating the Dataset on the {model_AE.name} before training.')\n",
    "timer.start()\n",
    "\n",
    "# evaluate once before training \n",
    "eval_step_AE(model_AE,\n",
    "             train_ds,\n",
    "             loss_function, \n",
    "             loss_metric=train_loss_metric)\n",
    "\n",
    "eval_step_AE(model_AE,  \n",
    "             test_ds,\n",
    "             loss_function, \n",
    "             loss_metric=test_loss_metric)\n",
    "\n",
    "# Evaluate the metrics\n",
    "train_loss = train_loss_metric.result()\n",
    "train_losses_AE.append(train_loss)\n",
    "test_loss = test_loss_metric.result()\n",
    "test_losses_AE.append(test_loss)\n",
    "\n",
    "train_loss_metric.reset_states()\n",
    "test_loss_metric.reset_states()\n",
    "\n",
    "# Evaluate the timer\n",
    "elapsed_time = timer.stop()\n",
    "times.append(elapsed_time)\n",
    "\n",
    "print(f'train_loss: {train_loss:0.4f}, test_loss: {test_loss:0.4f}')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\n[EPOCH] ____________________{epoch}____________________')\n",
    "    \n",
    "    timer.start()\n",
    "    \n",
    "    # Training step    \n",
    "    train_step_AE(model_AE, train_ds, loss_function, optimizer, train_loss_metric)\n",
    "    \n",
    "    # Test step    \n",
    "    img_original, img_reconstructed = eval_step_AE(model_AE, test_ds, loss_function, test_loss_metric)\n",
    "    \n",
    "    # Evaluate the metrics\n",
    "    test_loss = test_loss_metric.result()\n",
    "    test_losses_AE.append(test_loss)\n",
    "    train_loss = train_loss_metric.result()\n",
    "    train_losses_AE.append(train_loss)\n",
    "    \n",
    "    elapsed_time = timer.stop()\n",
    "    times.append(elapsed_time)\n",
    "\n",
    "    print(f'[{epoch}] - Finished Epoch in {elapsed_time:0.2f} seconds - train_loss: {train_loss:0.4f}; test_loss: {test_loss:0.4f}')\n",
    "    \n",
    "    # print progress every while\n",
    "    if epoch%5 == 0:\n",
    "        print(f'\\n[INFO] - Total time elapsed: {np.sum(times)/60:0.4f} min. Total time remaining: {(np.sum(times)/(epoch+1))*(EPOCHS-epoch-1)/60:0.4f} min.')\n",
    "        \n",
    "        # Visualize reconstructed image      \n",
    "        plt.figure(figsize=(9, 3))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.title('Original Image')\n",
    "        plt.imshow(img_original[0,:,:,0], cmap='gray')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.title('Reconstructed Image')\n",
    "        plt.imshow(img_reconstructed[0,:,:,0], cmap='gray')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "                       \n",
    "    # Resetting metrics \n",
    "    train_loss_metric.reset_states()\n",
    "    test_loss_metric.reset_states()\n",
    "\n",
    "print(f'\\n[INFO] - Total run time: {np.sum(times)/60:0.4f} min.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZto0hg_8IDW"
   },
   "source": [
    "## Visualize the losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "Gl_Sz0Oe1oBA",
    "outputId": "6ca7e2a4-073b-450a-9942-f8255a87da77",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20,7))\n",
    "\n",
    "x = np.arange(len(train_losses_AE))\n",
    "\n",
    "# losses\n",
    "axes.plot(x, train_losses_AE, label='train')\n",
    "axes.plot(x, test_losses_AE, label='test')\n",
    "axes.legend()\n",
    "axes.set(title='Losses', xlabel='Epoch', ylabel='loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUmuvfzy1oBB"
   },
   "source": [
    "# **Variational Autoencoder**\n",
    "\n",
    "The idea of a variational autoencoder is to force the learned representation of the input to be continuous with respect to their semantics. If we want to generate new unseen samples with the ordinary Autoencoder, we most likely would end up with a noise image that isn't meaningful.\n",
    "\n",
    "Essentially the Variational Autoencoder solves this by forcing the latent representation to be close to a normal distribution.\n",
    "\n",
    "(is this correct? What else is important to mention?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiVwfxCy1oBC"
   },
   "outputs": [],
   "source": [
    "class VEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,latent_dim):\n",
    "        super(VEncoder,self).__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, \n",
    "                                            kernel_size=3, \n",
    "                                            strides=(2, 2), \n",
    "                                            activation='relu')\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, \n",
    "                                            kernel_size=3, \n",
    "                                            strides=(2, 2),\n",
    "                                            activation='relu')\n",
    "        \n",
    "        self.flatten =  tf.keras.layers.Flatten()\n",
    "\n",
    "        self.latent_encoding = tf.keras.layers.Dense(latent_dim + latent_dim)\n",
    "\n",
    "    def call(self,x,training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.latent_encoding(x)\n",
    "        return x\n",
    "\n",
    "class VDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,latent_dim):\n",
    "        super(VDecoder,self).__init__()\n",
    "        \n",
    "        #self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1= tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu)\n",
    "\n",
    "        self.reshape = tf.keras.layers.Reshape(target_shape=(7, 7, 32))\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2DTranspose(filters=64, \n",
    "                                                     kernel_size=3, \n",
    "                                                     strides=2, \n",
    "                                                     padding='same',\n",
    "                                                     activation='relu')\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2DTranspose(filters=32, \n",
    "                                                     kernel_size=3, \n",
    "                                                     strides=2, \n",
    "                                                     padding='same',\n",
    "                                                     activation='relu')\n",
    "\n",
    "            # No activation\n",
    "        self.conv3 = tf.keras.layers.Conv2DTranspose(filters=1, \n",
    "                                                     kernel_size=3, \n",
    "                                                     strides=1, \n",
    "                                                     padding='same')\n",
    "        \n",
    "    def call(self,x,training=False):\n",
    "        #x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7IfotpQ1oBC"
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.encoder = VEncoder(latent_dim)\n",
    "        \n",
    "        self.decoder = VDecoder(latent_dim)\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None, training=False):\n",
    "        '''\n",
    "        sample a reconstrued image from CVAE.\n",
    "        :param eps: 2-D array(n, dim(latent_repr)), samples in latent_repr\n",
    "        :return: N-D array(batch_size, width, height, channel), reconstructed image\n",
    "        '''\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True, training=False)\n",
    "\n",
    "    def encode(self, x,training=False):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False,training=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9Q2gpmR1oBD"
   },
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi), axis=raxis)\n",
    "\n",
    "\n",
    "def elbo_loss(model, x, training=False):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7JGGaNR1oBD"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_VAE(model, train_ds, loss_function, optimizer, train_loss_metric):\n",
    "    '''\n",
    "    Training for one epoch. Adjusted for Autoencoder as there are no acc_metric.\n",
    "    '''\n",
    "    for img, label in train_ds:  # there are no (input,label) pairs\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            loss = loss_function(model, img, training=True)\n",
    "        \n",
    "        # backward pass\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # update metrics\n",
    "        train_loss_metric.update_state(loss)\n",
    "\n",
    "@tf.function\n",
    "def eval_step_VAE(model, ds, loss_function, loss_metric):\n",
    "    '''\n",
    "    Evaluate without training. Adjusted for autoencoder. \n",
    "    Return a random image and reconstructed version of it.\n",
    "    '''\n",
    "    # evaluate loss\n",
    "    for img, label in ds:\n",
    "        loss = loss_function(model, img)\n",
    "        loss_metric.update_state(loss)\n",
    "    \n",
    "    img = 0.0\n",
    "    prediction = 0.0\n",
    "   \n",
    "    # encode image\n",
    "    for img, label in ds.take(1):\n",
    "        mean, logvar = model.encode(img)\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        prediction = model.sample(z)\n",
    "    \n",
    "    return img, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2FvFI031oBE"
   },
   "source": [
    "## Set hyperparameters for the VAE\n",
    "\n",
    "- latent_dim gives the number of units the encoder produces that represent the mean and (log) variance of the encoded distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23WFubVd1oBE"
   },
   "outputs": [],
   "source": [
    "# @Hyperparameter\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 1e-4\n",
    "latent_dim = 10\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "timer = Timer()\n",
    "\n",
    "# Define @model\n",
    "input_shape = (None,28,28,1)\n",
    "model_VAE = CVAE(input_dim=input_shape, \n",
    "                 latent_dim= latent_dim)\n",
    "\n",
    "# Define @optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qz_a_M321oBE"
   },
   "outputs": [],
   "source": [
    "train_loss_metric = tf.keras.metrics.Mean('train_loss')\n",
    "test_loss_metric = tf.keras.metrics.Mean('test_loss')\n",
    "\n",
    "# Initialize lists for later visualization.\n",
    "train_losses_VAE = []\n",
    "test_losses_VAE = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ewmiIWRM1oBE",
    "outputId": "e154ffcf-9f5b-41d5-c775-3d6065816655"
   },
   "outputs": [],
   "source": [
    "print(f'[INFO] - Evaluating the Dataset on the {model_VAE.name} before training.')\n",
    "timer.start()\n",
    "\n",
    "# evaluate once before training \n",
    "eval_step_VAE(model_VAE,\n",
    "              train_ds, \n",
    "              elbo_loss,\n",
    "              loss_metric=train_loss_metric)\n",
    "\n",
    "eval_step_VAE(model_VAE,  \n",
    "              test_ds,\n",
    "              elbo_loss,\n",
    "              loss_metric=test_loss_metric)\n",
    "\n",
    "# update metrics\n",
    "train_loss = train_loss_metric.result()\n",
    "train_losses_VAE.append(train_loss)\n",
    "test_loss = test_loss_metric.result()\n",
    "test_losses_VAE.append(test_loss)\n",
    "train_loss_metric.reset_states()\n",
    "test_loss_metric.reset_states()\n",
    "\n",
    "# update timer\n",
    "elapsed_time = timer.stop()\n",
    "times.append(elapsed_time)\n",
    "\n",
    "print(f'train_loss: {train_loss:0.4f}, test_loss: {test_loss:0.4f}')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\n[EPOCH] ____________________{epoch}____________________')\n",
    "    \n",
    "    timer.start()\n",
    "    \n",
    "    # Training step    \n",
    "    train_step_VAE(model_VAE, train_ds, elbo_loss, optimizer, train_loss_metric)\n",
    "    \n",
    "    # Test step    \n",
    "    img_original, img_reconstructed = eval_step_VAE(model_VAE, test_ds, elbo_loss, test_loss_metric)\n",
    "    \n",
    "    # Evaluate the metrics\n",
    "    test_loss = test_loss_metric.result()\n",
    "    test_losses_VAE.append(test_loss)\n",
    "    train_loss = train_loss_metric.result()\n",
    "    train_losses_VAE.append(train_loss)\n",
    "    \n",
    "    # update timer\n",
    "    elapsed_time = timer.stop()\n",
    "    times.append(elapsed_time)\n",
    "\n",
    "    print(f'[{epoch}] - Finished Epoch in {elapsed_time:0.2f} seconds - train_loss: {train_loss:0.4f}; test_loss: {test_loss:0.4f}')\n",
    "    \n",
    "    # print progress every while\n",
    "    if epoch%5 == 0:\n",
    "        print(f'\\n[INFO] - Total time elapsed: {np.sum(times)/60:0.4f} min. Total time remaining: {(np.sum(times)/(epoch+1))*(EPOCHS-epoch-1)/60:0.4f} min.')\n",
    "        \n",
    "        # Visualize reconstructed image\n",
    "        plt.figure(figsize=(9, 3))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.title('Original Image')\n",
    "        plt.imshow(img_original[0,:,:,0], cmap='gray')\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.title('Reconstructed Image')\n",
    "        plt.imshow(img_reconstructed[0,:,:,0], cmap='gray')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Resetting metrics \n",
    "    train_loss_metric.reset_states()\n",
    "    test_loss_metric.reset_states()\n",
    "\n",
    "print(f'\\n[INFO] - Total run time: {np.sum(times)/60:0.4f} min.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "_6xTm4Rj1oBF",
    "outputId": "6f1a1677-7e41-4189-d88d-351b8a8919fe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20,7))\n",
    "\n",
    "x = np.arange(len(train_losses_VAE))\n",
    "\n",
    "# losses\n",
    "axes.plot(x, train_losses_VAE, label='train')\n",
    "axes.plot(x, test_losses_VAE, label='test')\n",
    "axes.legend()\n",
    "axes.set(title='Losses', xlabel='Epoch', ylabel='loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuWt_rdlPb7p"
   },
   "source": [
    "## Combining images\n",
    "\n",
    "- take the mean of two encodings of images.\n",
    "\n",
    "- if we want 80% of one image and 20% of another, we take the weighted mean instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZ1_2a__1oBG"
   },
   "source": [
    "- Here we use keras to load the Dataset instead of tfds.\n",
    "\n",
    "- We reimport the dataset for the visualization so we can have larger batches and no shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wFqVH5A1oBG"
   },
   "outputs": [],
   "source": [
    "(_, _), (test_x, test_y) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "test_x = tf.data.Dataset.from_tensor_slices(test_x)\n",
    "test_x = test_x.map(lambda img: tf.expand_dims(img, axis=-1))  # no channel dimension\n",
    "\n",
    "test_y = tf.data.Dataset.from_tensor_slices(test_y)\n",
    "test_ds_eval = tf.data.Dataset.zip((test_x, test_y))\n",
    "\n",
    "# preprocess without batches\n",
    "test_xy = preprocess_tfds(test_ds_eval, \n",
    "                          batch_size=1000, \n",
    "                          buffer_size=1000, \n",
    "                          prefetch_factor=None,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_xy= test_xy.take(1000) # take 10000 images for t-sne analysis instead of 1000. This gives better visibility of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vouT3oVmmGmD"
   },
   "source": [
    "Getting the embeddings for VAE and AE\n",
    "- converting label integers to string\n",
    "\n",
    "- for VAE we want two embeddings. One is reparameterized (for sampling images/decoding). The other (for t-sne) is just the mean of the encoded distribution. Reparameterization adds noise which leads to no clusters being visible in the t-sne plot for VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnsxbSMal-55"
   },
   "outputs": [],
   "source": [
    "\n",
    "latent_representation_AE = []\n",
    "labels_AE = []\n",
    "\n",
    "latent_representation_VAE = []\n",
    "latent_representation_VAE_TSNE = []\n",
    "\n",
    "labels_VAE = []\n",
    "\n",
    "\n",
    "for n, (img, label) in enumerate(test_xy):\n",
    "    if n == 0:\n",
    "        img0 = img\n",
    "    # for AE\n",
    "    latent_representation_AE.append(model_AE.encoder(img).numpy())\n",
    "    labels_AE.append(label)\n",
    "\n",
    "    # for VAE\n",
    "    mean,logvar = model_VAE.encode(img)\n",
    "    latent_representation_VAE.append(   \n",
    "                                       model_VAE.reparameterize(mean,logvar).numpy()\n",
    "                                                                                              )\n",
    "    latent_representation_VAE_TSNE.append( mean.numpy()   ) # for t-sne we look at the mean (since the reparameterization adds noise, which leads to clusters being invisible)\n",
    "\n",
    "    labels_VAE.append(label)\n",
    "\n",
    "\n",
    "\n",
    "# create an array with all representations and another array with the corresponding labels (as strings)\n",
    "\n",
    "latent_ds_AE = np.array(latent_representation_AE).reshape((-1, latent_dim))\n",
    "latent_labels_AE = np.array(labels_AE)\n",
    "latent_labels_AE = np.array(latent_labels_AE).reshape((-1))\n",
    "latent_labels_string_AE = [label_code[i] for i in latent_labels_AE]\n",
    "\n",
    "latent_ds_VAE = np.array(latent_representation_VAE).reshape((-1, 10))\n",
    "latent_ds_VAE_TSNE = np.array(latent_representation_VAE_TSNE).reshape((-1, 10))\n",
    "latent_labels_VAE = np.array(labels_VAE)\n",
    "latent_labels_VAE = np.array(latent_labels_VAE).reshape((-1))\n",
    "latent_labels_string_VAE = [label_code[i] for i in latent_labels_VAE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GnC87tH4I6m"
   },
   "source": [
    "## Interpolating between images\n",
    "Below we visualize an interpolation between two images. We also added an extra aspect (that was not required in the homework): noise. By adding noise to the combined latent representations and comparing the results, we want to show a property of VAE in contrast to AE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VySGAest8i6"
   },
   "outputs": [],
   "source": [
    "# select which two images should be interpolated and the weighting.\n",
    "ind0  = 1\n",
    "ind1  = 100\n",
    "rate = 0.5\n",
    "noise_level = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "0eZlUQEJh_U7",
    "outputId": "a919a729-5521-49b2-e112-e39789adaa3e"
   },
   "outputs": [],
   "source": [
    "interpol_repr_AE = (rate* latent_ds_AE[ind0] + (1-rate) * latent_ds_AE[ind1])\n",
    "interpol_repr_VAE = (rate* latent_ds_VAE[ind0] + (1-rate) * latent_ds_VAE[ind1])\n",
    "\n",
    "rec_img = model_AE.decoder(tf.expand_dims(interpol_repr_AE,axis=0))\n",
    "rec_img_VAE = model_VAE.sample(tf.expand_dims(interpol_repr_VAE,axis=0))\n",
    "\n",
    "# interpolated representations with noise added\n",
    "assert interpol_repr_AE.shape == interpol_repr_VAE.shape\n",
    "\n",
    "# normal distribution with zero mean for each dimension\n",
    "\n",
    "noise = np.random.multivariate_normal(mean = np.zeros(interpol_repr_AE.shape[0]),\n",
    "                                      cov = noise_level * np.eye(interpol_repr_AE.shape[0])).astype('float32')\n",
    "\n",
    "rec_img_noise = model_AE.decoder(tf.expand_dims(interpol_repr_AE + noise,axis=0))\n",
    "rec_img_VAE_noise = model_VAE.sample(tf.expand_dims(interpol_repr_VAE + noise,axis=0))\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3,nrows=2, figsize=(15,10))\n",
    "ax[0,0].imshow(img0[ind0,:,:,0], cmap='gray')\n",
    "ax[0,0].set_title(latent_labels_string_VAE[ind0])\n",
    "ax[1,0].imshow(img0[ind1,:,:,0], cmap='gray')\n",
    "ax[1,0].set_title(latent_labels_string_VAE[ind1])\n",
    "\n",
    "ax[0,1].imshow(rec_img[0,:,:,0], cmap='gray')\n",
    "ax[0,1].set_title(\"Autoencoder interpolation\")\n",
    "ax[1,1].imshow(rec_img_VAE[0,:,:,0],cmap='gray')\n",
    "ax[1,1].set_title(\"Variational Autoencoder interpolation\")\n",
    "\n",
    "ax[0,2].imshow(rec_img_noise[0,:,:,0],cmap=\"gray\")\n",
    "ax[0,2].set_title(\"Autoencoder interpolation + noise\")\n",
    "ax[1,2].imshow(rec_img_VAE_noise[0,:,:,0],cmap=\"gray\")\n",
    "ax[1,2].set_title(\"Variational Autoencoder interpolation + noise\")\n",
    "\n",
    "\n",
    "print('VAE: interpolated image of {} and {} at the right'.format(latent_labels_string_VAE[ind0],\n",
    "                                               latent_labels_string_VAE[ind1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqxT7otM4qDY"
   },
   "source": [
    "## Interpretation\n",
    "\n",
    "We can see that while the standard Autoencoder appears to be unaffected by the noise, the VAE reacts quite strongly to it.\n",
    "\n",
    "This can be seen as a feature rather than a bug. It means the VAE can generate new samples by slightly changing the representation. The learned latent representation space is in some sense continuous with it's semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrtSFf6X1oBJ"
   },
   "source": [
    "# t-SNE analysis of the learned encodings for both AE and VAE\n",
    "\n",
    "- We want to visualize the learned representations and how easily it is to differentiate between classes given these representations. \n",
    "\n",
    "- For this we want to represent encoded image vectors as a point in space (2D for visualization).\n",
    "\n",
    "- Since the learned representations of an image are of a dimensionality higher than 2 (here we chose 10), we can not simply represent each encoded image as a point on a cartesian coordinate system. \n",
    "\n",
    "- For this we reduce the dimensionality with t-sne. t-sne tries to keep distances between points. (so the distance between two encodings in higher dimensional space should roughly be the same as in the 2D projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA3OcnNi1oBI"
   },
   "outputs": [],
   "source": [
    "## fit and apply t-sne on the representations (from sci-kit learn)\n",
    "tsne_AE = TSNE(n_components=2, random_state=0)\n",
    "tsne_obj_AE= tsne_AE.fit_transform(latent_ds_AE)\n",
    "\n",
    "tsne_VAE = TSNE(n_components=2, random_state=0)\n",
    "tsne_obj_VAE= tsne_VAE.fit_transform(latent_ds_VAE_TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "IyF0IRPsVCRV",
    "outputId": "62ee3bf7-7228-451b-ec1b-6000fc5cf08e"
   },
   "outputs": [],
   "source": [
    "# plot for AE with seaborn\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "tsne_plot_AE = sns.scatterplot(x=tsne_obj_AE[:,0], \n",
    "                            y=tsne_obj_AE[:,1],\n",
    "                            hue=latent_labels_string_AE,\n",
    "                            palette=['purple','red','orange','brown','blue',\n",
    "                                    'dodgerblue','green','lightgreen','darkcyan', 'black'],\n",
    "                            legend='full')\n",
    "\n",
    "tsne_plot_AE.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "tsne_plot_AE.set_title('[Autoencoder] - t-SNE of the learned encodings', fontdict={'fontsize': 25})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plot for VAE\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "\n",
    "tsne_plot_VAE = sns.scatterplot(x=tsne_obj_VAE[:,0], \n",
    "                            y=tsne_obj_VAE[:,1],\n",
    "                            hue=latent_labels_string_VAE,\n",
    "                            palette=['purple','red','orange','brown','blue',\n",
    "                                    'dodgerblue','green','lightgreen','darkcyan', 'black'],\n",
    "                            legend='full')\n",
    "\n",
    "tsne_plot_VAE.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "tsne_plot_VAE.set_title('[Variational Autoencoder] - t-SNE of the learned encodings', fontdict={'fontsize': 25})\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzzUfcoVAYxV"
   },
   "source": [
    "## Interpretation\n",
    "\n",
    "We see that both the autoencoder and the variational Autoencoder have space in between their representations. One reason for this is that we have not displayed all data-points (all possible shoes, jackets etc. that exist). If it were, we would expect the VAE plot to be more densely packed compared to the AE plot. This is because VAE learns continuous latent distributions as the encoding. \n",
    "\n",
    "Above we have seen that adding noise to the latent encoding modified the result more strongly for the VAE compared to the AE. This showed that VAE can naturally encode any piece of cloth (e.g. a sandal-cloak mixup) with a normal distribution. So the output is in some sense expected to be continuous with respect to the latent representation while this is not the case for the normal Autoencoder."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder and Variational Autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06891ddacfc245c1a860e46f300b90eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4421e5821c06440bbf4be497337e7943",
       "IPY_MODEL_ebcc7fe1d0524f29919f29cc827121eb"
      ],
      "layout": "IPY_MODEL_6489162bfa7f4b9b932559142bb81b0a"
     }
    },
    "070b2469aa2d444ab1e8a0cb6ea5b30b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "101a4c28016c4db2aebe5cf60f15a35a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1636a3aa870b458fa413301b307f512f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16ed9de3c566481d8f7469b3d57e3612": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "190815918d004dd7969b9cb7a503f333": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_101a4c28016c4db2aebe5cf60f15a35a",
      "placeholder": "​",
      "style": "IPY_MODEL_f55a71d914dc4383bccd03933f5e0fb6",
      "value": " 4/4 [00:02&lt;00:00,  1.87 file/s]"
     }
    },
    "19949c5144fe43e4b3d82815f7261a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ea884b07a564303b74382607518ea69": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2266b6247f094792a175b1d9110cb726": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b00122e902f47acb3efbf06b99d3b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cd9ae82d0a24afb8aeabb51928ada0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "37370fbdcc6b450b9e70107b98cba3de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "417d43d404384f93a55340404abac399": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c55bbc1570f2482cb48cc0ee255cc852",
       "IPY_MODEL_c9b7dafd4802445889b49a824eb0fbad"
      ],
      "layout": "IPY_MODEL_1ea884b07a564303b74382607518ea69"
     }
    },
    "4421e5821c06440bbf4be497337e7943": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71d177dbec114f2cbf74135153e733af",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c1d03b23f9994dd594d5fd1f5f9e22a0",
      "value": 1
     }
    },
    "45e51560b0344064b2d84d032d9707ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a23418c746a04b7190e48c77279d7ddf",
      "placeholder": "​",
      "style": "IPY_MODEL_dcd2f74fbd3346da9d39cce1e4b2e463",
      "value": " 4/4 [00:02&lt;00:00,  1.82 url/s]"
     }
    },
    "57197cd3c12749bcbcbaf29115822a24": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a93ac3a8d084ad6ad7466789611421a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1636a3aa870b458fa413301b307f512f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6be9064c555e43e4b277244e626882c7",
      "value": 1
     }
    },
    "6489162bfa7f4b9b932559142bb81b0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65d1413674744bac90d12314e5e90bb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7489d97a46fb4b3f9caf473d8a2d8501",
       "IPY_MODEL_a47caff0061848989b819e522d5892bc"
      ],
      "layout": "IPY_MODEL_9567d646840543248b0dc8d3d6a09a4d"
     }
    },
    "6b24a422c3f64a8ca9844eb9b180ca41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6be9064c555e43e4b277244e626882c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "71602b6acecd4893925e5e91a72b3dc1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71d177dbec114f2cbf74135153e733af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7489d97a46fb4b3f9caf473d8a2d8501": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e12bfb8509394632be6df6925c55a919",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b65afa82be234799b3d4643ab6c024c0",
      "value": 1
     }
    },
    "760c95c778814d9c8795db0583c47ca3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f21df01f45d4188b10bb101bcd5b881": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e32119b111464c1fa2a5126c53b99fdd",
       "IPY_MODEL_cbf40dd55fe94557b07714399f80b5b3"
      ],
      "layout": "IPY_MODEL_2266b6247f094792a175b1d9110cb726"
     }
    },
    "8f58b8e60c6a41cea8e55ffaee31055c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb075f44d08647d7b781913516911e18",
       "IPY_MODEL_190815918d004dd7969b9cb7a503f333"
      ],
      "layout": "IPY_MODEL_6b24a422c3f64a8ca9844eb9b180ca41"
     }
    },
    "9567d646840543248b0dc8d3d6a09a4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "961fcc4f2bca4014a21795406dc34269": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 86%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f31e0b6fecec44048fca88c5bb66add1",
      "max": 60000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0545e3500824a198185c2c9e9ef4f95",
      "value": 51856
     }
    },
    "a23418c746a04b7190e48c77279d7ddf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47caff0061848989b819e522d5892bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57197cd3c12749bcbcbaf29115822a24",
      "placeholder": "​",
      "style": "IPY_MODEL_19949c5144fe43e4b3d82815f7261a78",
      "value": " 60000/0 [00:23&lt;00:00, 3445.97 examples/s]"
     }
    },
    "a4ded38fb51343d68abf61b666d8076e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_961fcc4f2bca4014a21795406dc34269",
       "IPY_MODEL_d12a7e6f15484c82a891d45e7a1db468"
      ],
      "layout": "IPY_MODEL_fc4c2575df944c7e8e7fd67bf1d4e76c"
     }
    },
    "a51383a98da64edb8d67a4202e98ad91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa293d870d2b494aa01226dfc38ee6bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "aac72d8c71fa4e0e99e8d0cf705d3aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "adfc802f6b224aabb69a90c004e822a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a93ac3a8d084ad6ad7466789611421a",
       "IPY_MODEL_45e51560b0344064b2d84d032d9707ea"
      ],
      "layout": "IPY_MODEL_d7c4e0f5448d4f4a94be99ffbcc65bb5"
     }
    },
    "b65afa82be234799b3d4643ab6c024c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bd32c1cc2a9b4df786dc300f7b22347c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0545e3500824a198185c2c9e9ef4f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c1d03b23f9994dd594d5fd1f5f9e22a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c55bbc1570f2482cb48cc0ee255cc852": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Size...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6cbbe9fece9467d972486c68fbb4542",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa293d870d2b494aa01226dfc38ee6bd",
      "value": 1
     }
    },
    "c72192de951442e08987b349d2c0c4c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9b7dafd4802445889b49a824eb0fbad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_760c95c778814d9c8795db0583c47ca3",
      "placeholder": "​",
      "style": "IPY_MODEL_2b00122e902f47acb3efbf06b99d3b28",
      "value": " 29/29 [00:02&lt;00:00, 13.35 MiB/s]"
     }
    },
    "cbf40dd55fe94557b07714399f80b5b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71602b6acecd4893925e5e91a72b3dc1",
      "placeholder": "​",
      "style": "IPY_MODEL_a51383a98da64edb8d67a4202e98ad91",
      "value": " 0/10000 [00:00&lt;?, ? examples/s]"
     }
    },
    "d12a7e6f15484c82a891d45e7a1db468": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16ed9de3c566481d8f7469b3d57e3612",
      "placeholder": "​",
      "style": "IPY_MODEL_aac72d8c71fa4e0e99e8d0cf705d3aec",
      "value": " 51856/60000 [00:00&lt;00:00, 120764.99 examples/s]"
     }
    },
    "d6cbbe9fece9467d972486c68fbb4542": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7c4e0f5448d4f4a94be99ffbcc65bb5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcd2f74fbd3346da9d39cce1e4b2e463": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e12bfb8509394632be6df6925c55a919": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e32119b111464c1fa2a5126c53b99fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37370fbdcc6b450b9e70107b98cba3de",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ee04a7ed1d6e442a804e4d349ad03f6a",
      "value": 0
     }
    },
    "ebcc7fe1d0524f29919f29cc827121eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd32c1cc2a9b4df786dc300f7b22347c",
      "placeholder": "​",
      "style": "IPY_MODEL_070b2469aa2d444ab1e8a0cb6ea5b30b",
      "value": " 10000/0 [00:03&lt;00:00, 3197.58 examples/s]"
     }
    },
    "ee04a7ed1d6e442a804e4d349ad03f6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f31e0b6fecec44048fca88c5bb66add1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f55a71d914dc4383bccd03933f5e0fb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb075f44d08647d7b781913516911e18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Extraction completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c72192de951442e08987b349d2c0c4c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2cd9ae82d0a24afb8aeabb51928ada0a",
      "value": 1
     }
    },
    "fc4c2575df944c7e8e7fd67bf1d4e76c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
