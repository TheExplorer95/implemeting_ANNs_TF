{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nxYuSRm5XDYa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "configure_gpu_options()\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "def configure_gpu_options():\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "def transform_to_wav(filepaths, directory_name):\n",
    "    for path in filepaths:\n",
    "        # files\n",
    "\n",
    "        dst = path.replace(directory_name, directory_name + \"_mono_wav\").replace(\"mp3\",\"wav\")\n",
    "\n",
    "        # convert wav to mp3                                             \n",
    "        sound = AudioSegment.from_mp3(path)\n",
    "        l = sound.split_to_mono()\n",
    "        sound = l[np.random.randint(0,2)] # randomly take first or second channel\n",
    "        sound = sound.set_frame_rate(1000)\n",
    "        sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-Xa3vMgXyJW"
   },
   "outputs": [],
   "source": [
    "!cd /content/drive/MyDrive/MusicGenreClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeu146XDZDXD"
   },
   "outputs": [],
   "source": [
    "paths = listdir(\"/content/drive/MyDrive/MusicGenreClassification\")\n",
    "\n",
    "paths = [\"/content/drive/MyDrive/MusicGenreClassification/\" + p for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvmFicPyBuiL"
   },
   "outputs": [],
   "source": [
    "\"\"\"all_mp3 = []\n",
    "for path in paths:\n",
    "    files = listdir(path)\n",
    "    for file in files:\n",
    "        all_mp3.append(path + file)\n",
    "print(len(all_mp3))\n",
    "\n",
    "filepaths = all_mp3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV9Bt5egzigT"
   },
   "outputs": [],
   "source": [
    "# check for broken/corrupted audio files\n",
    "\n",
    "for file in filepaths:\n",
    "    try:\n",
    "        a = tf.io.read_file(file)\n",
    "        a,sr = tf.audio.decode_wav(a, desired_samples = 22050*30 )\n",
    "        b = tfio.audio.resample(a,22050, 4000)\n",
    "\n",
    "    except:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cHwX1uT8WTQ"
   },
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary, original_sr, desired_sr, duration):\n",
    "    \"\"\"decodes wav file and applies sub- or supersampling to achieve a desired sampling rate\"\"\"\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary, desired_samples = duration * original_sr)\n",
    "    audio = tfio.audio.resample(audio, original_sr, desired_sr)\n",
    "    return tf.squeeze(audio, axis=-1), desired_sr\n",
    "\n",
    "# get filenames\n",
    "#filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "\n",
    "def data_generator():\n",
    "    \"\"\"\n",
    "    Relies on a global argument dictionary\n",
    "\n",
    "    T: number of time-steps to use for the context embedding c_t\n",
    "\n",
    "    k: number of future time-steps to predict\n",
    "\n",
    "    N: number of samples (1 positive + N-1 negative samples)\n",
    "\n",
    "    window_duration: window duration in seconds\n",
    "\n",
    "    original_sr: sampling rate of original audio files\n",
    "\n",
    "    desired_sr: sampling rate as input to CPC (used for subsampling)\n",
    "\n",
    "    duration: assumed full duration of an audio file (30s, files get truncated or padded with zeros)\n",
    "\n",
    "    filepaths: list of all filepaths to all audio files\n",
    "    \"\"\"\n",
    "    global data_generator_arguments\n",
    "    T = data_generator_arguments[\"T\"]\n",
    "    k = data_generator_arguments[\"k\"]\n",
    "    N = data_generator_arguments[\"N\"]\n",
    "    window_duration = data_generator_arguments[\"window_duration\"]\n",
    "    original_sr = data_generator_arguments[\"original_sr\"]\n",
    "    desired_sr = data_generator_arguments[\"desired_sr\"]\n",
    "    duration = data_generator_arguments[\"full_duration\"]\n",
    "    filepaths = data_generator_arguments[\"filepaths\"]\n",
    "\n",
    "    while True: \n",
    "\n",
    "        #randomly select sample filepaths from list for N samples\n",
    "        samples = random.sample(filepaths, N)\n",
    "        positive_sample = samples[0]\n",
    "        negative_samples = samples[1:]\n",
    "\n",
    "        # take full 30 seconds of positive sample\n",
    "        positive_audio = tf.io.read_file(positive_sample)\n",
    "        positive_audio, sample_rate = decode_audio(positive_audio, original_sr, \n",
    "                                                   desired_sr, duration)\n",
    "\n",
    "        window_size = int(sample_rate * window_duration)\n",
    "        positive_audio = tf.reshape(positive_audio, (T+k, window_size, 1))\n",
    "\n",
    "        # negative samples (find a way to do it without a for loop pls)\n",
    "        sample_tensors = []\n",
    "        sample_tensors.append(positive_audio)\n",
    "\n",
    "        for ns in negative_samples:\n",
    "            ns = tf.io.read_file(ns)\n",
    "            ns, sample_rate = decode_audio(ns, original_sr,\n",
    "                                           desired_sr, duration)\n",
    "\n",
    "            # cut to 30s\n",
    "            window_size = int(sample_rate * window_duration)\n",
    "\n",
    "            ns = tf.reshape(ns, (T+k,window_size,1))\n",
    "\n",
    "            # only take the last k entries (better: a random part of the audio)\n",
    "            ns = ns[T:T+k]\n",
    "\n",
    "            sample_tensors.append(ns)\n",
    "\n",
    "        # concatenate all tensors, making its shape (T+k*N, window_size,1)\n",
    "        data = tf.concat(sample_tensors, axis= 0)\n",
    "\n",
    "        yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNiQumfMZ-wn",
    "outputId": "4ef82c4c-81d7-4187-d968-2ea902a93801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4000, 1)\n"
     ]
    }
   ],
   "source": [
    "files = listdir(\"/content/drive/MyDrive/MusicGenreClassification\")\n",
    "\n",
    "filepaths = [\"/content/drive/MyDrive/MusicGenreClassification/\" + f for f in files]\n",
    "\n",
    "\n",
    "\n",
    "data_generator_arguments = {\n",
    "    \"T\" : 20,\n",
    "    \"k\" : 10,\n",
    "    \"N\" : 8,\n",
    "    \"window_duration\" : 1,\n",
    "    \"full_duration\" : 30,\n",
    "    \"original_sr\" : 22050,\n",
    "    \"desired_sr\" : 4000,\n",
    "    \"filepaths\" : filepaths\n",
    "    }\n",
    "\n",
    "DataGen = data_generator()\n",
    "\n",
    "print(next(DataGen).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JFUOyIhVp5Z"
   },
   "outputs": [],
   "source": [
    "T = data_generator_arguments[\"T\"]\n",
    "k = data_generator_arguments[\"k\"]\n",
    "N = data_generator_arguments[\"N\"]\n",
    "sampling_rate = data_generator_arguments[\"desired_sr\"]\n",
    "window_duration = data_generator_arguments[\"window_duration\"]\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "data_shape = (T+k*N, sampling_rate * window_duration, 1)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(generator = data_generator, \n",
    "                                    output_signature = tf.TensorSpec(data_shape, \n",
    "                                                                     dtype=tf.dtypes.float32, name=None)\n",
    "                                    )\n",
    "\n",
    "train_ds = train_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjjjr_dISjU_"
   },
   "outputs": [],
   "source": [
    "z_dim = 256  # latent dim z_t\n",
    "c_dim = 512  # dim of g_ar output c_t\n",
    "\n",
    "class Encoder (tf.keras.Model):\n",
    "    '''\n",
    "    g_enc: strided 1d convolution\n",
    "    '''\n",
    "\n",
    "    def __init__ (self, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        s = [5,4,2,2,2]  # stride sizes\n",
    "        k = [10,8,4,4,4]  # kernel sizes\n",
    "        f = [128,128,128,128,128]  # num filters\n",
    "\n",
    "        # input dim: [batch, T+K*N, d, 1]\n",
    "        self.enc_layers = []\n",
    "        for l in range(5):\n",
    "            self.enc_layers.append(tf.keras.layers.Conv1D(f[l],k[l],s[l]))\n",
    "            self.enc_layers.append(tf.keras.layers.BatchNormalization())\n",
    "            self.enc_layers.append(tf.keras.layers.LeakyReLU())\n",
    "        self.enc_layers.append(tf.keras.layers.GlobalAveragePooling1D())\n",
    "        self.enc_layers.append(tf.keras.layers.Dense(z_dim, activation='tanh'))\n",
    "        # ouput dim:[batch, T+K*N, z]\n",
    "    @tf.function\n",
    "    def call (self, x, training):\n",
    "        \n",
    "        for l in self.enc_layers:\n",
    "            try:  # batch normalization \n",
    "                x = l(x, training)\n",
    "            except:\n",
    "                x = l(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Autoregressive (tf.keras.Model):\n",
    "    '''\n",
    "    g_ar: GRU RNN\n",
    "    '''\n",
    "\n",
    "    def __init__ (self, c_dim):\n",
    "        super(Autoregressive, self).__init__()\n",
    "        # input dim: [batch, T, z]\n",
    "        self.gru = tf.keras.layers.GRU(c_dim, name='ar_context') \n",
    "        # output dim:[batch, c] since return_seq is False\n",
    "    @tf.function\n",
    "    def call (self, z):\n",
    "        return self.gru(z)\n",
    "\n",
    "\n",
    "class Predict_z (tf.keras.layers.Layer):\n",
    "    '''\n",
    "    transformation of c_t, currently linear (W_k) for all future timesteps\n",
    "    '''\n",
    "\n",
    "    def __init__ (self, z_dim, K):\n",
    "        super(Predict_z, self).__init__()\n",
    "        \n",
    "        # input_dim: [batch, c]\n",
    "        self.transform_layers = []\n",
    "        for k in range(K):  # k different layers for each timestep\n",
    "            self.transform_layers.append(tf.keras.layers.Dense(z_dim)) \n",
    "    #@tf.function\n",
    "    def call(self, c_t):\n",
    "        # TODO: maybe size should be multidimensional\n",
    "        z_pred = tf.TensorArray(tf.float32, size=len(self.transform_layers))\n",
    "        for l in tf.range(len(self.transform_layers)):  \n",
    "            z_pred = z_pred.write(l, self.transform_layers[l](c_t))  # apply for each k\n",
    "            z_pred_t = z_pred.stack()\n",
    "            # [K, batch, z]\n",
    "        return tf.transpose(z_pred_t, perm=[1,0,2])  # output_dim: [batch, K, z]\n",
    "\n",
    "#@tf.function\n",
    "def compute_f (z, z_pred):\n",
    "    '''\n",
    "    compute f following eq(3) in the paper to be batch (K x N) matrices.\n",
    "    First column is the postive sample.\n",
    "    '''\n",
    "\n",
    "    # z input dim: [batch, K, N, z], \n",
    "    z = tf.expand_dims(z, axis=-2)  # [batch, K, N, 1, z]\n",
    "    \n",
    "    # z_pred input dim: [batch, K, z]\n",
    "    pred = tf.repeat(z_pred, repeats=z.shape[2], axis=-2)  # [batch, K*N, z]\n",
    "    pred = tf.reshape(pred, shape=[z.shape[0],z.shape[1],z.shape[2],z.shape[-1]])  # [batch, K, N, z]\n",
    "    pred = tf.expand_dims(pred, axis=-1)  # [batch, K, N, z, 1]\n",
    "\n",
    "    dot_prod = tf.linalg.matmul(z, pred)  # [batch, K, N, 1, 1]\n",
    "    dot_prod = tf.squeeze(dot_prod, axis=[-2,-1])  # [batch, K, N]\n",
    "    dot_prod = tf.exp(dot_prod)\n",
    "    return dot_prod  # output dim: [batch, K, N]\n",
    "\n",
    "\n",
    "class CPC (tf.keras.models.Model):\n",
    "    '''\n",
    "    put everything together. Return f_k for every k\n",
    "    '''\n",
    "\n",
    "    def __init__ (self, num_time_observations, num_time_future, num_negative_samples, z_dim, c_dim):\n",
    "        super(CPC, self).__init__()\n",
    "        self.T = num_time_observations\n",
    "        self.K = num_time_future\n",
    "        self.N = num_negative_samples\n",
    "        self.z = z_dim\n",
    "        self.c = c_dim\n",
    "\n",
    "        self.g_enc = Encoder(self.z)\n",
    "        self.g_ar = Autoregressive(self.c)\n",
    "        self.p_z = Predict_z(z_dim=self.z, K=self.K)\n",
    "    #@tf.function\n",
    "    def call(self, x, training=False):  \n",
    "        # input dim: [batch, T+K*N, d, 1]\n",
    "        #print('input dim: ', x.shape)\n",
    "        # Embedding\n",
    "        z_t = tf.keras.layers.TimeDistributed( # dim 1 is the temporal dim \n",
    "            self.g_enc)(x, training=training)  # [batch, T+K*N, z]\n",
    "        #print('embedding dim: ', z_t.shape)    \n",
    "        \n",
    "\n",
    "        # Split current observation embeddings and future embeddings\n",
    "        z_obs = z_t[:, :self.T]  # t = {0,...,T}, dim: [batch, T, z]\n",
    "        z_future = z_t[:, self.T:]  # t = {T+1,,,T+K} for N samples, dim:[batch, K*N, z]\n",
    "        z_future = tf.reshape(z_future, [-1, self.K, self.N, self.z])  # [batch, K, N, z]\n",
    "        #print('embedding obs:', z_obs.shape)\n",
    "        #print('embedding pred:', z_future.shape)\n",
    "\n",
    "        # Predict embeddings\n",
    "        c_T = self.g_ar(z_obs)  # [batch, c]\n",
    "        #print('context:', c_T.shape)\n",
    "        z_pred = self.p_z(c_T)  # [batch, K, z]\n",
    "        #print('transformed_context:', z_pred.shape)\n",
    "\n",
    "        # Compute f matrices\n",
    "        f_mat = compute_f(z_future, z_pred)  # [batch, K, N]\n",
    "\n",
    "        return f_mat\n",
    "\n",
    "\n",
    "\n",
    "cpc = CPC(T, k, N, z_dim, c_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPILFCYLTfga"
   },
   "outputs": [],
   "source": [
    "class InfoNCE (tf.keras.losses.Loss):\n",
    "    '''\n",
    "    Compute loss given batch times f matrices with dim (K x N)\n",
    "    '''\n",
    "\n",
    "    def __call__(self, f):\n",
    "        # input dim: [batch, K, N]\n",
    "        denominator = tf.reduce_sum(f, axis=2)  # [batch, K]\n",
    "        losses = - tf.math.log(f[:,:,0] / denominator)  # first column is positive\n",
    "        return tf.reduce_mean(tf.reduce_mean(losses, axis=1),axis=-1)  # [batch]. Take a mean over k timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjvqrMiVTmjC"
   },
   "outputs": [],
   "source": [
    "loss = InfoNCE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15H1N7HNRsXJ"
   },
   "outputs": [],
   "source": [
    "for i in train_ds.take(1):\n",
    "    nce_loss = loss(cpc(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Sc1dwM5Ug2O",
    "outputId": "5f403f4a-a65c-439e-d206-d59dd21f711b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.07944274\n"
     ]
    }
   ],
   "source": [
    "tf.print(nce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0E9jI_KnX_Ht"
   },
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(model, ds, loss_function, optimizer, \n",
    "               steps_per_epoch, train_loss_metric=None, \n",
    "               train_acc_metric= None):\n",
    "    '''\n",
    "    Training for one epoch.\n",
    "    '''\n",
    "\n",
    "    for batch in ds.take(steps_per_epoch): # use 100 batch per epoch\n",
    "        # forward pass with GradientTape\n",
    "        with tf.GradientTape() as tape:\n",
    "            prediction = model(batch)\n",
    "            loss = loss_function(prediction)\n",
    "\n",
    "        # backward pass via GradienTape (auto-gradient calc)\n",
    "        if not tf.math.is_nan(loss):\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # update metrics\n",
    "            if train_loss_metric is not None:\n",
    "                train_loss_metric.update_state(loss)\n",
    "            if train_acc_metric is not None:\n",
    "                train_acc_metric.update_state(target, prediction)\n",
    "        else:\n",
    "            tf.print(\"loss is nan, no parameters updated\")\n",
    "            tf.print(\"f_matrix:\", prediction)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "ctI54xO8X_wS",
    "outputId": "de58b08e-4c21-435a-d3bc-905f208760ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is nan, no parameters updated\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-bd05c87e0bbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-663fbf9abe83>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, ds, loss_function, optimizer, steps_per_epoch, train_loss_metric, train_acc_metric)\u001b[0m\n\u001b[1;32m      7\u001b[0m     '''\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# use 100 batch per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# forward pass with GradientTape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_loss_metric = tf.keras.metrics.Mean('train_loss')\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_step(cpc, train_ds, loss, optimizer, 1, train_loss_metric)\n",
    "\n",
    "    if e%10 == 0:\n",
    "        print(train_loss_metric.result().numpy())\n",
    "        train_loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGNG50JmX_0i",
    "outputId": "e424f360-fa37-4993-996e-daaddeecd7c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1d_30/kernel:0' shape=(10, 1, 128) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_30/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_30/gamma:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_30/beta:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv1d_31/kernel:0' shape=(8, 128, 128) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_31/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_31/gamma:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_31/beta:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv1d_32/kernel:0' shape=(4, 128, 128) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_32/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_32/gamma:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_32/beta:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv1d_33/kernel:0' shape=(4, 128, 128) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_33/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_33/gamma:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_33/beta:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv1d_34/kernel:0' shape=(4, 128, 128) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan],\n",
       "         [nan, nan, nan, ..., nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_34/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_34/gamma:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_34/beta:0' shape=(128,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_66/kernel:0' shape=(128, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'dense_66/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_30/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_30/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_31/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_31/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_32/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_32/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_33/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_33/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_34/moving_mean:0' shape=(128,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'batch_normalization_34/moving_variance:0' shape=(128,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Variable 'ar_context/gru_cell_6/kernel:0' shape=(256, 1536) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'ar_context/gru_cell_6/recurrent_kernel:0' shape=(512, 1536) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'ar_context/gru_cell_6/bias:0' shape=(2, 1536) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_67/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_67/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_68/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_68/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_69/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_69/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_70/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_70/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_71/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_71/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_72/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_72/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_73/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_73/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_74/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_74/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_75/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_75/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_76/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'cpc_7/predict_z_6/dense_76/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>]"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4enDvkNX_5g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpBL3A13XIrN"
   },
   "outputs": [],
   "source": [
    "# get all filenames\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "\n",
    "# split filenames into test, train and val set\n",
    "train_files = filenames[:6400]\n",
    "val_files = filenames[6400: 6400 + 800]\n",
    "test_files = filenames[-800:]\n",
    "\n",
    "# load audio\n",
    "def decode_audio(audio_binary):\n",
    "  audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "  return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "#get label for filepath\n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "\n",
    "  # Note: You'll use indexing here instead of tuple unpacking to enable this \n",
    "  # to work in a TensorFlow graph.\n",
    "  return parts[-2]\n",
    "\n",
    "# get both waveform and label for a filepath\n",
    "def get_waveform_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return waveform, label\n",
    "\n",
    "# make a tf dataset for the train files\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# get spectrogram for audio file\n",
    "def get_spectrogram(waveform):\n",
    "  # Padding for files with less than 16000 samples\n",
    "  zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
    "\n",
    "  # Concatenate audio with padding so that all audio clips will be of the \n",
    "  # same length\n",
    "  waveform = tf.cast(waveform, tf.float32)\n",
    "  equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "  spectrogram = tf.signal.stft(\n",
    "      equal_length, frame_length=255, frame_step=128)\n",
    "\n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "  return spectrogram\n",
    "\n",
    "# plot spectrogram and waveform for audio file\n",
    "for waveform, label in waveform_ds.take(1):\n",
    "  label = label.numpy().decode('utf-8')\n",
    "  spectrogram = get_spectrogram(waveform)\n",
    "\n",
    "print('Label:', label)\n",
    "print('Waveform shape:', waveform.shape)\n",
    "print('Spectrogram shape:', spectrogram.shape)\n",
    "print('Audio playback')\n",
    "# show audio file in notebook\n",
    "display.display(display.Audio(waveform, rate=16000))\n",
    "\n",
    "\n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "  # Convert to frequencies to log scale and transpose so that the time is\n",
    "  # represented in the x-axis (columns).\n",
    "  log_spec = np.log(spectrogram.T)\n",
    "  height = log_spec.shape[0]\n",
    "  X = np.arange(16000, step=height + 1)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, figsize=(12, 8))\n",
    "timescale = np.arange(waveform.shape[0])\n",
    "axes[0].plot(timescale, waveform.numpy())\n",
    "axes[0].set_title('Waveform')\n",
    "axes[0].set_xlim([0, 16000])\n",
    "plot_spectrogram(spectrogram.numpy(), axes[1])\n",
    "axes[1].set_title('Spectrogram')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# turn waveform dataset into spectrogram dataset\n",
    "\n",
    "def get_spectrogram_and_label_id(audio, label):\n",
    "  spectrogram = get_spectrogram(audio)\n",
    "  spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "  label_id = tf.argmax(label == commands)\n",
    "  return spectrogram, label_id\n",
    "\n",
    "spectrogram_ds = waveform_ds.map(\n",
    "    get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# combine preprocessing into one function from files to spectrogram dataset\n",
    "def preprocess_dataset(files, spectrogram=False):\n",
    "  files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "  output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "  if spectrogram:\n",
    "    output_ds = output_ds.map(\n",
    "        get_spectrogram_and_label_id,  num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "  return output_ds\n",
    "\n",
    "# preprocess data\n",
    "train_ds = preprocess_dataset(train_files)\n",
    "val_ds = preprocess_dataset(val_files)\n",
    "test_ds = preprocess_dataset(test_files)\n",
    "\n",
    "\n",
    "# plot a confusion matrix for the predictions/classifications\n",
    "\n",
    "test_audio = []\n",
    "test_labels = []\n",
    "\n",
    "for audio, label in test_ds:\n",
    "  test_audio.append(audio.numpy())\n",
    "  test_labels.append(label.numpy())\n",
    "\n",
    "test_audio = np.array(test_audio)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "y_true = test_labels\n",
    "\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred) \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands, \n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcjzwIsJgW14"
   },
   "outputs": [],
   "source": [
    "# Sampling rate: 22.050 instead of 16000, 16bit mono wav\n",
    "\n",
    "# multiply audio waveform by tf.signal.hamming_window(window_size)\n",
    "\n",
    "# use a 5 second window. window_size =  5 * sampling_rate\n",
    "\n",
    "# randomly choose positive sample (1 or multiple?) from all filenames (then choose a 5 second window randomly from the 30s song)\n",
    "\n",
    "# randomly choose N-1 negative samples (also 5 second window) from all other files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvMyctgzsKYp"
   },
   "outputs": [],
   "source": [
    "# Model (output of call function is the InfoNCE loss)\n",
    "\n",
    "class CPC(tf.keras.Model):\n",
    "    def __init__(self, k_steps):\n",
    "        super(CPC,self).__init__()\n",
    "\n",
    "        # number of timesteps to predict\n",
    "        self.k_steps = k_steps\n",
    "\n",
    "        # encoder: transforms windows of the audio into embeddings up to z_t\n",
    "        self.g_enc = Encoder()\n",
    "\n",
    "        # autoregressive model: predicts c_t based on z_t of the past k-steps into the future\n",
    "        self.g_ar = AutoRegressive()\n",
    "\n",
    "        # k times W for each z_t prediction\n",
    "        self.linear_projections = [tf.keras.layers.Dense(output_size) for i in tf.range(k_steps)]\n",
    "\n",
    "    def call(self, X):\n",
    "\n",
    "        # process every window in X to get an embedding c_t (for positive and for negative samples)\n",
    "        pass\n",
    "\n",
    "        # process every embedding c_t with g_ar to calculate all z_t+k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBcdYz_W7XHn"
   },
   "source": [
    "### f score calculation\n",
    "![grafik.png](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "### f score meaning\n",
    "\n",
    "![grafik.png](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "\n",
    "### maximizing correct f score vs incorrect f scores means maximizing mutual information between z_tk and c_t\n",
    "\n",
    "![grafik.png](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "### InfoNCE loss: maximize mutual information between correct future timestep encoding and past context and minimize mutual information between false future timestep encoding and past context\n",
    "\n",
    "![grafik.png](data:image/png;base64,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)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Contrastive Predictive Coding",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
